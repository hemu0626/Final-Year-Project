<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Mu He" />


<title>Random Forest and Examples</title>

<script src="site_libs/header-attrs-2.8/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>








<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Final Year Project</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="fyp_outline.html">Final Year Project Outline</a>
</li>
<li>
  <a href="adsm.html">Advanced Statistical Methods</a>
</li>
<li>
  <a href="survival.html">Survival Analysis</a>
</li>
<li>
  <a href="epidemiology.html">Epidemiology</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Random Forest and Examples</h1>
<h4 class="author">Mu He</h4>
<h4 class="date">9/18/2021</h4>

</div>


<div id="random-forest" class="section level3">
<h3>Random Forest</h3>
<p>Definition a random forest</p>
</div>
<div id="flowchart-of-a-random-forest-alogrithm" class="section level3">
<h3>Flowchart of a Random Forest Alogrithm</h3>
</div>
<div id="examples-in-r" class="section level3">
<h3>Examples in R</h3>
<pre class="r"><code>library(randomForest)</code></pre>
<pre><code>## randomForest 4.6-14</code></pre>
<pre><code>## Type rfNews() to see new features/changes/bug fixes.</code></pre>
<pre class="r"><code>library(MASS)
library(tree)</code></pre>
<pre><code>## Registered S3 method overwritten by &#39;tree&#39;:
##   method     from
##   print.tree cli</code></pre>
<pre class="r"><code>library(gbm)</code></pre>
<pre><code>## Loaded gbm 2.1.8</code></pre>
<pre class="r"><code>library(e1071)

par(mfrow=c(1,1))
# Plot for M/3 explanation
n&lt;-10:1000
plot(n,((n-1)/n)^n,typ=&quot;l&quot;)</code></pre>
<p><img src="randomforest_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<pre class="r"><code>dev.print(device=postscript, &quot;M3.eps&quot;, onefile=FALSE, horizontal=FALSE)</code></pre>
<pre><code>## png 
##   2</code></pre>
<pre class="r"><code>### Boston example, based on example from James et al.(2013)
library(randomForest)
library(MASS)
library(tree)
# First, a tree
#?Boston
set.seed(1)
train = sample(1:nrow(Boston), nrow(Boston)/2)
tree.boston=tree(medv~.,Boston,subset=train)
summary(tree.boston)</code></pre>
<pre><code>## 
## Regression tree:
## tree(formula = medv ~ ., data = Boston, subset = train)
## Variables actually used in tree construction:
## [1] &quot;rm&quot;    &quot;lstat&quot; &quot;crim&quot;  &quot;age&quot;  
## Number of terminal nodes:  7 
## Residual mean deviance:  10.38 = 2555 / 246 
## Distribution of residuals:
##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -10.1800  -1.7770  -0.1775   0.0000   1.9230  16.5800</code></pre>
<pre class="r"><code># Use cv tree to determine depth (i.e., to see if we might want to prune)
plot(tree.boston)
text(tree.boston,pretty=0)</code></pre>
<p><img src="randomforest_files/figure-html/unnamed-chunk-1-2.png" width="672" /></p>
<pre class="r"><code>cv.boston=cv.tree(tree.boston)
plot(cv.boston$size,cv.boston$dev,type=&#39;b&#39;)</code></pre>
<p><img src="randomforest_files/figure-html/unnamed-chunk-1-3.png" width="672" /></p>
<pre class="r"><code>#This is how we would prune:
#prune.boston=prune.tree(tree.boston,best=5)
#yhat=predict(prune.boston,newdata=Boston[-train,])
yhat=predict(tree.boston,newdata=Boston[-train,])
boston.test=Boston[-train,&quot;medv&quot;]
plot(yhat,boston.test)
abline(0,1)</code></pre>
<p><img src="randomforest_files/figure-html/unnamed-chunk-1-4.png" width="672" /></p>
<pre class="r"><code>mean((yhat-boston.test)^2)</code></pre>
<pre><code>## [1] 35.28688</code></pre>
<pre class="r"><code># Now, bagging and random forests
set.seed(1)
train = sample (1: nrow(Boston ), nrow(Boston )/2)
bag.boston=randomForest(medv~.,data=Boston,subset=train,mtry=13,importance=TRUE)
bag.boston</code></pre>
<pre><code>## 
## Call:
##  randomForest(formula = medv ~ ., data = Boston, mtry = 13, importance = TRUE,      subset = train) 
##                Type of random forest: regression
##                      Number of trees: 500
## No. of variables tried at each split: 13
## 
##           Mean of squared residuals: 11.33119
##                     % Var explained: 85.26</code></pre>
<pre class="r"><code>yhat.bag = predict(bag.boston,newdata=Boston[-train,])
mean((yhat.bag-boston.test)^2)</code></pre>
<pre><code>## [1] 23.4579</code></pre>
<pre class="r"><code>plot(yhat.bag,boston.test)
abline(0,1)</code></pre>
<p><img src="randomforest_files/figure-html/unnamed-chunk-1-5.png" width="672" /></p>
<pre class="r"><code>importance(bag.boston)</code></pre>
<pre><code>##           %IncMSE IncNodePurity
## crim    21.162661    813.209885
## zn       5.838995     64.533390
## indus    2.410295    103.424195
## chas    -2.847136      9.601055
## nox     16.137234    239.949497
## rm      53.339469  12383.514326
## age     18.048751    319.950062
## dis      8.004047    254.610410
## rad      2.376173     67.816948
## tax      9.718104    139.453388
## ptratio  6.159605    110.896968
## black    6.830931    227.195328
## lstat   48.633719   4846.537272</code></pre>
<pre class="r"><code>varImpPlot(bag.boston)</code></pre>
<p><img src="randomforest_files/figure-html/unnamed-chunk-1-6.png" width="672" /></p>
<pre class="r"><code>set.seed(1)
rf.boston=randomForest(medv~.,data=Boston,subset=train,mtry=4,importance=TRUE)
rf.boston</code></pre>
<pre><code>## 
## Call:
##  randomForest(formula = medv ~ ., data = Boston, mtry = 4, importance = TRUE,      subset = train) 
##                Type of random forest: regression
##                      Number of trees: 500
## No. of variables tried at each split: 4
## 
##           Mean of squared residuals: 10.23441
##                     % Var explained: 86.69</code></pre>
<pre class="r"><code>yhat.rf = predict(rf.boston,newdata=Boston[-train,])
mean((yhat.rf-boston.test)^2)</code></pre>
<pre><code>## [1] 18.11686</code></pre>
<pre class="r"><code>importance(rf.boston)</code></pre>
<pre><code>##           %IncMSE IncNodePurity
## crim    15.372334    1220.14856
## zn       3.335435     194.85945
## indus    6.964559    1021.94751
## chas     2.059298      69.68099
## nox     14.009761    1005.14707
## rm      28.693900    6162.30720
## age     13.832143     708.55138
## dis     10.317731     852.33701
## rad      4.390624     162.22597
## tax      7.536563     564.60422
## ptratio  9.333716    1163.39624
## black    8.341316     355.62445
## lstat   27.132450    5549.25088</code></pre>
<pre class="r"><code>varImpPlot(rf.boston)
rf.boston2=randomForest(medv~.,data=Boston,subset=train,mtry=6,importance=TRUE,ntree=500)
rf.boston2</code></pre>
<pre><code>## 
## Call:
##  randomForest(formula = medv ~ ., data = Boston, mtry = 6, importance = TRUE,      ntree = 500, subset = train) 
##                Type of random forest: regression
##                      Number of trees: 500
## No. of variables tried at each split: 6
## 
##           Mean of squared residuals: 9.926383
##                     % Var explained: 87.09</code></pre>
<pre class="r"><code>yhat.rf = predict(rf.boston2,newdata=Boston[-train,])
mean((yhat.rf-boston.test)^2)</code></pre>
<pre><code>## [1] 19.27921</code></pre>
<pre class="r"><code>importance(rf.boston)</code></pre>
<pre><code>##           %IncMSE IncNodePurity
## crim    15.372334    1220.14856
## zn       3.335435     194.85945
## indus    6.964559    1021.94751
## chas     2.059298      69.68099
## nox     14.009761    1005.14707
## rm      28.693900    6162.30720
## age     13.832143     708.55138
## dis     10.317731     852.33701
## rad      4.390624     162.22597
## tax      7.536563     564.60422
## ptratio  9.333716    1163.39624
## black    8.341316     355.62445
## lstat   27.132450    5549.25088</code></pre>
<pre class="r"><code>varImpPlot(rf.boston)</code></pre>
<p><img src="randomforest_files/figure-html/unnamed-chunk-1-7.png" width="672" /></p>
<pre class="r"><code># Boosting -- this is just the little bit from class, see wine.R for a fuller example of boosting
set.seed(1)
boost.boston=gbm(medv~.,data=Boston[train,],distribution=&quot;gaussian&quot;,n.trees=5000,interaction.depth=4)
summary(boost.boston)</code></pre>
<p><img src="randomforest_files/figure-html/unnamed-chunk-1-8.png" width="672" /></p>
<pre><code>##             var    rel.inf
## rm           rm 43.9919329
## lstat     lstat 33.1216941
## crim       crim  4.2604167
## dis         dis  4.0111090
## nox         nox  3.4353017
## black     black  2.8267554
## age         age  2.6113938
## ptratio ptratio  2.5403035
## tax         tax  1.4565654
## indus     indus  0.8008740
## rad         rad  0.6546400
## zn           zn  0.1446149
## chas       chas  0.1443986</code></pre>
<pre class="r"><code>par(mfrow=c(1,2))
plot(boost.boston,i=&quot;rm&quot;)</code></pre>
<p><img src="randomforest_files/figure-html/unnamed-chunk-1-9.png" width="672" /></p>
<pre class="r"><code>plot(boost.boston,i=&quot;lstat&quot;)</code></pre>
<p><img src="randomforest_files/figure-html/unnamed-chunk-1-10.png" width="672" /></p>
<pre class="r"><code>yhat.boost=predict(boost.boston,newdata=Boston[-train,],n.trees=5000)
boston.test=Boston[-train,&quot;medv&quot;]
mean((yhat.boost-boston.test)^2)</code></pre>
<pre><code>## [1] 18.84709</code></pre>
<pre class="r"><code>### Hitters data
data(Hitters,package=&quot;ISLR&quot;)
head(Hitters)</code></pre>
<pre><code>##                   AtBat Hits HmRun Runs RBI Walks Years CAtBat CHits
## -Andy Allanson      293   66     1   30  29    14     1    293    66
## -Alan Ashby         315   81     7   24  38    39    14   3449   835
## -Alvin Davis        479  130    18   66  72    76     3   1624   457
## -Andre Dawson       496  141    20   65  78    37    11   5628  1575
## -Andres Galarraga   321   87    10   39  42    30     2    396   101
## -Alfredo Griffin    594  169     4   74  51    35    11   4408  1133
##                   CHmRun CRuns CRBI CWalks League Division PutOuts
## -Andy Allanson         1    30   29     14      A        E     446
## -Alan Ashby           69   321  414    375      N        W     632
## -Alvin Davis          63   224  266    263      A        W     880
## -Andre Dawson        225   828  838    354      N        E     200
## -Andres Galarraga     12    48   46     33      N        E     805
## -Alfredo Griffin      19   501  336    194      A        W     282
##                   Assists Errors Salary NewLeague
## -Andy Allanson         33     20     NA         A
## -Alan Ashby            43     10  475.0         N
## -Alvin Davis           82     14  480.0         A
## -Andre Dawson          11      3  500.0         N
## -Andres Galarraga      40      4   91.5         N
## -Alfredo Griffin      421     25  750.0         A</code></pre>
<pre class="r"><code>Hitters&lt;-na.omit(Hitters)
Hitters$logSalary&lt;-log(Hitters$Salary)
names(Hitters)</code></pre>
<pre><code>##  [1] &quot;AtBat&quot;     &quot;Hits&quot;      &quot;HmRun&quot;     &quot;Runs&quot;      &quot;RBI&quot;      
##  [6] &quot;Walks&quot;     &quot;Years&quot;     &quot;CAtBat&quot;    &quot;CHits&quot;     &quot;CHmRun&quot;   
## [11] &quot;CRuns&quot;     &quot;CRBI&quot;      &quot;CWalks&quot;    &quot;League&quot;    &quot;Division&quot; 
## [16] &quot;PutOuts&quot;   &quot;Assists&quot;   &quot;Errors&quot;    &quot;Salary&quot;    &quot;NewLeague&quot;
## [21] &quot;logSalary&quot;</code></pre>
<pre class="r"><code>str(Hitters)</code></pre>
<pre><code>## &#39;data.frame&#39;:    263 obs. of  21 variables:
##  $ AtBat    : int  315 479 496 321 594 185 298 323 401 574 ...
##  $ Hits     : int  81 130 141 87 169 37 73 81 92 159 ...
##  $ HmRun    : int  7 18 20 10 4 1 0 6 17 21 ...
##  $ Runs     : int  24 66 65 39 74 23 24 26 49 107 ...
##  $ RBI      : int  38 72 78 42 51 8 24 32 66 75 ...
##  $ Walks    : int  39 76 37 30 35 21 7 8 65 59 ...
##  $ Years    : int  14 3 11 2 11 2 3 2 13 10 ...
##  $ CAtBat   : int  3449 1624 5628 396 4408 214 509 341 5206 4631 ...
##  $ CHits    : int  835 457 1575 101 1133 42 108 86 1332 1300 ...
##  $ CHmRun   : int  69 63 225 12 19 1 0 6 253 90 ...
##  $ CRuns    : int  321 224 828 48 501 30 41 32 784 702 ...
##  $ CRBI     : int  414 266 838 46 336 9 37 34 890 504 ...
##  $ CWalks   : int  375 263 354 33 194 24 12 8 866 488 ...
##  $ League   : Factor w/ 2 levels &quot;A&quot;,&quot;N&quot;: 2 1 2 2 1 2 1 2 1 1 ...
##  $ Division : Factor w/ 2 levels &quot;E&quot;,&quot;W&quot;: 2 2 1 1 2 1 2 2 1 1 ...
##  $ PutOuts  : int  632 880 200 805 282 76 121 143 0 238 ...
##  $ Assists  : int  43 82 11 40 421 127 283 290 0 445 ...
##  $ Errors   : int  10 14 3 4 25 7 9 19 0 22 ...
##  $ Salary   : num  475 480 500 91.5 750 ...
##  $ NewLeague: Factor w/ 2 levels &quot;A&quot;,&quot;N&quot;: 2 1 2 2 1 1 1 2 1 1 ...
##  $ logSalary: num  6.16 6.17 6.21 4.52 6.62 ...
##  - attr(*, &quot;na.action&quot;)= &#39;omit&#39; Named int [1:59] 1 16 19 23 31 33 37 39 40 42 ...
##   ..- attr(*, &quot;names&quot;)= chr [1:59] &quot;-Andy Allanson&quot; &quot;-Billy Beane&quot; &quot;-Bruce Bochte&quot; &quot;-Bob Boone&quot; ...</code></pre>
<pre class="r"><code>Hitters&lt;-Hitters[,-19]
names(Hitters)</code></pre>
<pre><code>##  [1] &quot;AtBat&quot;     &quot;Hits&quot;      &quot;HmRun&quot;     &quot;Runs&quot;      &quot;RBI&quot;      
##  [6] &quot;Walks&quot;     &quot;Years&quot;     &quot;CAtBat&quot;    &quot;CHits&quot;     &quot;CHmRun&quot;   
## [11] &quot;CRuns&quot;     &quot;CRBI&quot;      &quot;CWalks&quot;    &quot;League&quot;    &quot;Division&quot; 
## [16] &quot;PutOuts&quot;   &quot;Assists&quot;   &quot;Errors&quot;    &quot;NewLeague&quot; &quot;logSalary&quot;</code></pre>
<pre class="r"><code>set.seed(1)
train = sample (1: nrow(Hitters), nrow(Hitters)/2)
tree.hitters &lt;- tree(logSalary ~ ., data = Hitters, subset=train)
summary(tree.hitters)</code></pre>
<pre><code>## 
## Regression tree:
## tree(formula = logSalary ~ ., data = Hitters, subset = train)
## Variables actually used in tree construction:
## [1] &quot;CAtBat&quot;   &quot;Assists&quot;  &quot;Walks&quot;    &quot;HmRun&quot;    &quot;Division&quot;
## Number of terminal nodes:  8 
## Residual mean deviance:  0.1944 = 23.91 / 123 
## Distribution of residuals:
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
## -1.4670 -0.2460  0.0038  0.0000  0.2132  2.4030</code></pre>
<pre class="r"><code>plot(tree.hitters)
text(tree.hitters)
yhat=predict(tree.hitters,newdata=Hitters[-train,])
hitters.test=Hitters[-train,&quot;logSalary&quot;]
plot(yhat,hitters.test)
abline(0,1)</code></pre>
<p><img src="randomforest_files/figure-html/unnamed-chunk-1-11.png" width="672" /></p>
<pre class="r"><code>mean((yhat-hitters.test)^2)</code></pre>
<pre><code>## [1] 0.275614</code></pre>
<pre class="r"><code># Now, bagging and random forests
set.seed(1)
bag.hitters=randomForest(logSalary~.,data=Hitters,subset=train,mtry=19,importance=TRUE)
bag.hitters</code></pre>
<pre><code>## 
## Call:
##  randomForest(formula = logSalary ~ ., data = Hitters, mtry = 19,      importance = TRUE, subset = train) 
##                Type of random forest: regression
##                      Number of trees: 500
## No. of variables tried at each split: 19
## 
##           Mean of squared residuals: 0.2514973
##                     % Var explained: 67.7</code></pre>
<pre class="r"><code>yhat.bag = predict(bag.hitters,newdata=Hitters[-train,])
mean((yhat.bag-hitters.test)^2)</code></pre>
<pre><code>## [1] 0.1750964</code></pre>
<pre class="r"><code>importance(bag.hitters)</code></pre>
<pre><code>##               %IncMSE IncNodePurity
## AtBat      7.26020380     3.3118887
## Hits      -1.74250877     2.6813779
## HmRun      4.99876015     2.1273678
## Runs       6.92650711     2.1890659
## RBI        3.23777281     3.0187084
## Walks      8.00519716     3.5902254
## Years      7.54512973     1.3222528
## CAtBat    12.91107389    18.0087183
## CHits      9.82212081    12.3866514
## CHmRun     5.59286383     3.1458876
## CRuns     14.86923592    20.6911231
## CRBI      12.63812713    15.6724989
## CWalks     9.12974681     9.0983980
## League    -0.08615830     0.1736580
## Division   0.31213577     0.1362073
## PutOuts    1.20674704     1.1597453
## Assists    0.78879314     0.7665019
## Errors    -0.07427328     0.5192243
## NewLeague  0.21072397     0.1237044</code></pre>
<pre class="r"><code>varImpPlot(bag.hitters)</code></pre>
<p><img src="randomforest_files/figure-html/unnamed-chunk-1-12.png" width="672" /></p>
<pre class="r"><code>plot(yhat.bag,hitters.test)
abline(0,1)
set.seed(1)
rf.hitters=randomForest(logSalary~.,data=Hitters,subset=train,mtry=5,importance=TRUE)
rf.hitters</code></pre>
<pre><code>## 
## Call:
##  randomForest(formula = logSalary ~ ., data = Hitters, mtry = 5,      importance = TRUE, subset = train) 
##                Type of random forest: regression
##                      Number of trees: 500
## No. of variables tried at each split: 5
## 
##           Mean of squared residuals: 0.2435802
##                     % Var explained: 68.72</code></pre>
<pre class="r"><code>yhat.rf = predict(rf.hitters,newdata=Hitters[-train,])
mean((yhat.rf-hitters.test)^2)</code></pre>
<pre><code>## [1] 0.1796161</code></pre>
<pre class="r"><code>importance(rf.hitters)</code></pre>
<pre><code>##               %IncMSE IncNodePurity
## AtBat      5.36446661     3.6657072
## Hits       3.74747317     3.6856706
## HmRun      3.93054695     2.1896637
## Runs       5.17512756     2.6250355
## RBI        4.24151568     3.1925397
## Walks      7.67285241     3.6715738
## Years      8.11996800     3.8397646
## CAtBat    13.37862850    16.4216520
## CHits     12.51628261    15.1740994
## CHmRun     6.18618982     4.9753254
## CRuns     12.46371946    15.4218965
## CRBI      12.16966307    12.5002084
## CWalks     9.70728599     9.7808236
## League     1.16037977     0.1819858
## Division   0.68279716     0.1450699
## PutOuts    1.57928623     1.0987496
## Assists   -0.47528239     0.8565811
## Errors     0.09964008     0.7053460
## NewLeague  2.44937229     0.1757951</code></pre>
<pre class="r"><code>varImpPlot(rf.hitters)</code></pre>
<p><img src="randomforest_files/figure-html/unnamed-chunk-1-13.png" width="672" /><img src="randomforest_files/figure-html/unnamed-chunk-1-14.png" width="672" /></p>
<pre class="r"><code>#A figure
M&lt;-(1:20)*50
error&lt;-M
for(m in M){
    bag.hitters=randomForest(logSalary~.,data=Hitters,subset=train,mtry=19,importance=TRUE,ntree=m)
    yhat.bag = predict(bag.hitters,newdata=Hitters[-train,])
    error[m/50]&lt;-mean((yhat.bag-hitters.test)^2)
}
bag&lt;-error
for(m in M){
    bag.hitters=randomForest(logSalary~.,data=Hitters,subset=train,mtry=9,importance=TRUE,ntree=m)
    yhat.bag = predict(bag.hitters,newdata=Hitters[-train,])
    error[m/50]&lt;-mean((yhat.bag-hitters.test)^2)
}
rf4&lt;-error
for(m in M){
    bag.hitters=randomForest(logSalary~.,data=Hitters,subset=train,mtry=5,importance=TRUE,ntree=m)
    yhat.bag = predict(bag.hitters,newdata=Hitters[-train,])
    error[m/50]&lt;-mean((yhat.bag-hitters.test)^2)
}
rf6&lt;-error
plot(M,bag,typ=&quot;l&quot;,col=2,xlim=c(0,1000),ylab=&quot;test error&quot;,ylim=c(0.145,0.2))
lines(M,rf4,typ=&quot;l&quot;,col=1)
lines(M,rf6,typ=&quot;l&quot;,col=4)
legend(1,0.165,c(&quot;m=19 (bagging)&quot;,&quot;m=9&quot;,&quot;m=5&quot;),col=c(2,1,4),pch=c(2,3,4))
# Boosting for Hitters data --- this is the little bit from class; see wine.R data for a fuller example of boosting
set.seed(1)
boost.hitters=gbm(logSalary~.,data=Hitters[train,],distribution=&quot;gaussian&quot;,n.trees=5000,interaction.depth=4)
summary(boost.hitters)</code></pre>
<p><img src="randomforest_files/figure-html/unnamed-chunk-1-15.png" width="672" /></p>
<pre><code>##                 var    rel.inf
## CRBI           CRBI 25.2977851
## PutOuts     PutOuts  7.1116163
## CHmRun       CHmRun  7.0615629
## CHits         CHits  7.0541211
## Assists     Assists  6.7865919
## CWalks       CWalks  6.7637158
## CRuns         CRuns  5.9402874
## RBI             RBI  4.0395929
## HmRun         HmRun  3.9852742
## Walks         Walks  3.8762873
## Years         Years  3.8625979
## AtBat         AtBat  3.6221973
## CAtBat       CAtBat  3.5911514
## Runs           Runs  3.4584062
## Hits           Hits  2.8939522
## Errors       Errors  1.9371690
## Division   Division  1.1253812
## League       League  1.0560439
## NewLeague NewLeague  0.5362659</code></pre>
<pre class="r"><code>yhat.boost=predict(boost.hitters,newdata=Hitters[-train,],n.trees=5000)
hitters.test=Hitters[-train,&quot;logSalary&quot;]
mean((yhat.boost-hitters.test)^2)</code></pre>
<pre><code>## [1] 0.2837507</code></pre>
<pre class="r"><code>### Iris data
names(iris)</code></pre>
<pre><code>## [1] &quot;Sepal.Length&quot; &quot;Sepal.Width&quot;  &quot;Petal.Length&quot; &quot;Petal.Width&quot; 
## [5] &quot;Species&quot;</code></pre>
<pre class="r"><code>set.seed(1)
train &lt;- c(sample(1:50, 25), sample(51:100, 25), sample(101:150, 25))
tree.iris &lt;- tree(Species ~ ., data = iris, subset=train,method=&quot;class&quot;)
summary(tree.iris)</code></pre>
<pre><code>## 
## Classification tree:
## tree(formula = Species ~ ., data = iris, subset = train, method = &quot;class&quot;)
## Variables actually used in tree construction:
## [1] &quot;Petal.Length&quot; &quot;Petal.Width&quot; 
## Number of terminal nodes:  4 
## Residual mean deviance:  0.09479 = 6.73 / 71 
## Misclassification error rate: 0.02667 = 2 / 75</code></pre>
<pre class="r"><code>plot(tree.iris)
text(tree.iris)</code></pre>
<p><img src="randomforest_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code>iris.test=iris[-train,&quot;Species&quot;]
iris.pred=predict(tree.iris,iris[-train,],type=&quot;class&quot;)
tab&lt;-table(iris.test,iris.pred)
tab</code></pre>
<pre><code>##             iris.pred
## iris.test    setosa versicolor virginica
##   setosa         25          0         0
##   versicolor      0         21         4
##   virginica       0          1        24</code></pre>
<pre class="r"><code>1-classAgreement(tab)$diag</code></pre>
<pre><code>## [1] 0.06666667</code></pre>
<pre class="r"><code>classAgreement(tab)$crand</code></pre>
<pre><code>## [1] 0.8154798</code></pre>
<pre class="r"><code># Now, bagging and random forests
set.seed(1)
bag.iris=randomForest(Species~.,data=iris,subset=train,mtry=4,importance=TRUE,type=&quot;class&quot;)
bag.iris</code></pre>
<pre><code>## 
## Call:
##  randomForest(formula = Species ~ ., data = iris, mtry = 4, importance = TRUE,      type = &quot;class&quot;, subset = train) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 4
## 
##         OOB estimate of  error rate: 5.33%
## Confusion matrix:
##            setosa versicolor virginica class.error
## setosa         25          0         0        0.00
## versicolor      0         23         2        0.08
## virginica       0          2        23        0.08</code></pre>
<pre class="r"><code>iris.pred=predict(bag.iris,iris[-train,],type=&quot;class&quot;)
tab&lt;-table(iris.test,iris.pred)
tab</code></pre>
<pre><code>##             iris.pred
## iris.test    setosa versicolor virginica
##   setosa         25          0         0
##   versicolor      0         23         2
##   virginica       0          1        24</code></pre>
<pre class="r"><code>1-classAgreement(tab)$diag</code></pre>
<pre><code>## [1] 0.04</code></pre>
<pre class="r"><code>classAgreement(tab)$crand</code></pre>
<pre><code>## [1] 0.8841001</code></pre>
<pre class="r"><code>set.seed(1)
rf.iris=randomForest(Species~.,data=iris,subset=train,mtry=3,importance=TRUE,type=&quot;class&quot;)
rf.iris</code></pre>
<pre><code>## 
## Call:
##  randomForest(formula = Species ~ ., data = iris, mtry = 3, importance = TRUE,      type = &quot;class&quot;, subset = train) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 3
## 
##         OOB estimate of  error rate: 5.33%
## Confusion matrix:
##            setosa versicolor virginica class.error
## setosa         25          0         0        0.00
## versicolor      0         23         2        0.08
## virginica       0          2        23        0.08</code></pre>
<pre class="r"><code>iris.pred.rf=predict(rf.iris,iris[-train,],type=&quot;class&quot;)
tab&lt;-table(iris.test,iris.pred.rf)
tab</code></pre>
<pre><code>##             iris.pred.rf
## iris.test    setosa versicolor virginica
##   setosa         25          0         0
##   versicolor      0         23         2
##   virginica       0          1        24</code></pre>
<pre class="r"><code>1-classAgreement(tab)$diag</code></pre>
<pre><code>## [1] 0.04</code></pre>
<pre class="r"><code>classAgreement(tab)$crand</code></pre>
<pre><code>## [1] 0.8841001</code></pre>
<pre class="r"><code>importance(rf.iris)</code></pre>
<pre><code>##                setosa versicolor  virginica MeanDecreaseAccuracy
## Sepal.Length  0.00000  -2.871920 -0.1927267            -1.928877
## Sepal.Width   0.00000  -5.745376  1.1175273            -2.964702
## Petal.Length 22.03275  32.368649 30.8482956            36.767047
## Petal.Width  23.66448  26.470187 22.9210198            30.263067
##              MeanDecreaseGini
## Sepal.Length        0.4490572
## Sepal.Width         0.6211415
## Petal.Length       26.9239773
## Petal.Width        21.3627306</code></pre>
<pre class="r"><code>varImpPlot(rf.iris)</code></pre>
<p><img src="randomforest_files/figure-html/unnamed-chunk-2-2.png" width="672" /></p>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3,h4",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
